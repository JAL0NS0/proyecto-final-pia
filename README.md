# üëÅÔ∏è SenseLink-AI: Modelo de Detecci√≥n de Riesgos Urbanos en el Borde

![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)
![YOLO11](https://img.shields.io/badge/AI-YOLO11n-green.svg)
![Edge AI](https://img.shields.io/badge/Task-Edge_Computing-purple.svg)
![Status](https://img.shields.io/badge/Status-Modelo_Validado-success.svg)

**SenseLink-AI** es un modelo de visi√≥n artificial de alto rendimiento y baja latencia, dise√±ado espec√≠ficamente para **asistencia a personas con discapacidad visual**. 

Este proyecto se centra en la **optimizaci√≥n de redes neuronales** (basado en YOLO11n) para ejecutar detecci√≥n de objetos cr√≠ticos en hardware con recursos limitados (como la Raspberry Pi Zero 2 W), permitiendo su implementaci√≥n en diversos dispositivos finales (wearables, bastones inteligentes o apps m√≥viles) sin dependencia de internet.

---

## üìã Tabla de Contenidos
1. [El Reto T√©cnico](#-el-reto-t√©cnico)
2. [Arquitectura del Modelo](#-arquitectura-del-modelo)
3. [Ingenier√≠a de Datos](#-ingenier√≠a-de-datos)
4. [Benchmark de Rendimiento](#-benchmark-de-rendimiento)
5. [Instalaci√≥n e Inferencia](#-instalaci√≥n-e-inferencia)
6. [Estructura del Repositorio](#-estructura-del-repositorio)

---

## üö© El Reto T√©cnico
La detecci√≥n de peligros urbanos (como baches o sem√°foros a√©reos) es cr√≠tica para la seguridad de personas ciegas. Sin embargo, los modelos de detecci√≥n actuales suelen ser:
1.  **Muy pesados:** Requieren GPUs potentes que no caben en un dispositivo port√°til.
2.  **Dependientes de la Nube:** Introducen latencia y requieren conexi√≥n constante, lo cual es peligroso en cruces de calle.

**El objetivo de SenseLink-AI** es democratizar la seguridad visual creando un modelo capaz de correr *offline* en procesadores econ√≥micos de <$15 USD.

---

## üí° Arquitectura del Modelo
Este proyecto implementa una pipeline de entrenamiento y optimizaci√≥n enfocada en **Edge Computing**:

* **Core:** YOLO11n (Nano), seleccionado por su balance entre precisi√≥n y velocidad.
* **Resoluci√≥n Adaptativa:** Entrenado con variantes de tama√±o de entrada (320px vs 640px) para seleccionar modelo que maximice FPS en CPUs ARM.
* **Versatilidad de Despliegue:** El modelo exportado es agn√≥stico al hardware final; sirve como "backend" de visi√≥n para cualquier aplicaci√≥n de asistencia.
* **Robustez Ambiental:** Capaz de generalizar en condiciones de baja iluminaci√≥n y clima adverso.

### Clases Cr√≠ticas Detectadas
El modelo se especializa en 7 objetos de riesgo/inter√©s vial:
1.  `semaforo_verde` ‚úÖ (Cruce seguro)
2.  `semaforo_rojo` üõë (Peligro)
3.  `semaforo_amarillo` ‚ö†Ô∏è (Precauci√≥n)
4.  `escaleras` ü™ú (Riesgo de ca√≠da)
5.  `zebra` ü¶ì (Zona de cruce)
6.  `podotactil` üõ§Ô∏è (Gu√≠a de suelo)
7.  `bache` üï≥Ô∏è (Irregularidad peligrosa)

---

## üß† Ingenier√≠a de Datos

La mayor contribuci√≥n t√©cnica de este proyecto reside en la curaci√≥n y aumento del dataset para situaciones del mundo real:

### 1. Balanceo de Clases Adaptativo
Se abord√≥ el desbalance nativo de datasets urbanos (donde abundan sem√°foros pero escasean baches) mediante un script propio de **Data Augmentation Selectivo**:
* **Clases Mayoritarias:** Preservadas para evitar sobreajuste.
* **Clases Cr√≠ticas (Baches/Amarillo):** Multiplicadas **8x - 12x** sint√©ticamente.

### 2. Simulaci√≥n de Entorno (Albumentations)
Para garantizar que el modelo funcione cuando el usuario m√°s lo necesita (mal clima), se entren√≥ con transformaciones avanzadas:
* üåßÔ∏è **Lluvia y Niebla Sint√©tica:** Robustez ante clima adverso.
* üí® **Motion Blur:** Simulaci√≥n del movimiento de la c√°mara al caminar.
* üåë **Ruido de Sensor:** Simulaci√≥n de c√°maras de baja calidad en entornos oscuros.

> **Estrategia de Aumentaci√≥n:**
> ![Data Augmentation](docs/imgs/data_aumentation.png)
> ![Data Augmentation2](docs/imgs/data_aumentation2.png)
> *(Figura 1: Entrenamiento robusto mediante inyecci√≥n de ruido y clima sint√©tico)*

---

## ‚ö° Benchmark de Rendimiento (Target: RPi Zero 2 W)

Se evaluaron dos variantes del modelo para determinar la viabilidad en el borde:

| Modelo | Input Size | Precisi√≥n (mAP@50) | Latencia (T4 GPU) |
| :--- | :--- | :--- | :--- |
| **SenseLink-AI Fast** | **320x320** | **0.797** | **~7.72ms** |
| SenseLink-AI High | 640x640 | [0.883] | ~7.95ms |

*El modelo **Fast (320px)** fue seleccionado como la versi√≥n estable para despliegue.*

## ‚öôÔ∏è Instalaci√≥n e Inferencia

Este repositorio incluye una aplicaci√≥n web de demostraci√≥n (basada en Streamlit) para interactuar con el modelo f√°cilmente.

### 1\. Clonar el repositorio

```bash
git clone https://github.com/TU_USUARIO/SenseLink.git
cd SenseLink
```

### 2\. Instalar Dependencias

Se recomienda utilizar un entorno virtual (venv):

```bash
pip install -r requirements.txt
```

### 3\. Ejecutar Demo (Interfaz Gr√°fica)

Para iniciar la interfaz web local, cargar im√°genes/videos y ver las m√©tricas de inferencia en tiempo real:

```bash
streamlit run app.py
```

*Esto abrir√° autom√°ticamente una pesta√±a en tu navegador en `http://localhost:8501`.*

-----

## üë• Autores y Cr√©ditos

  * **Desarrollo del Modelo:** Joaquin Alonso Marroquin Amaya
  * **Curso:** Capstone Project - Postgrado en Inteligencia Artificial, Universidad Galileo
  * **Herramientas:** Ultralytics YOLO, Albumentations, Roboflow
